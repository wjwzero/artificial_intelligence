## Thinking1: 在推荐系统中，FM和MF哪个应用的更多，为什么？
- FM Factorization Machine 因子分解机； MF Matric Factorization 矩阵分解；
    - MF在推荐系统中能解决将User-Item评分矩阵中的已知值对矩阵进行分解，根据分解后的矩阵重新计算评分矩阵来预测。MF所能够利用的信息，只有关系矩阵，无法利用其它特征。
    - FM矩阵进行了one-hot变化作为特征，是的特征维度巨大而稀疏，引入了更多辅助信息作为特征，并可根据特征与特征之间的关心进行预测。
    - MF可看做FM的特例，从特征角度，FM比MF应用更广泛。在推荐过程中需要考虑和计算过个维度的特征及其之间的关系，FM较MF更准确。
    
## Thinking2: FFM与FM有哪些区别？
- FFM Field-aware Factorization machines 可领域感知的银子分解机。FFM就是在FM的基础上增加领域感知功能
    - FM在做计算和预测时考虑了特征与特征之间的关系，但所表示的只是特征与特征的关系
    - FFM在计算特征是做出标注，加入了特征与领域(Field)的组合，是算法具有感知领域信息的能力
    
## Thinking3: DeepFM相比于FM解决了哪些问题，原理是怎样的？
- DeepFM保留了FM的特性，突破了FM在有限时间内只能及计算最高二阶特征组合的限制，不进可以考虑一阶和二阶特征，还可以计算更高阶的特征。
- DeepFM设计了一个End-toEnd模型结构，充分利用深度学习特征抽取的有事，省去认为特征工程的步骤。
- DeepFM的数据输入层是稀疏的基于One-hot编码的一阶特征层，接下来数据进入Dense Embeddings层，将特征做embedding学习表示为相同的维度k，通过Dense Embeding 层后，在FM层计算一阶特征即原始特征相加以及二阶特征即过embedding后的向量两两内积。平行的在Deep层，每个embedding向量做级联，然后做多层的全连接，学习更深的特征。在最后的输出层，将FM层输出与Deep层输出进行级联，接一个Dense层，作为最终输出结果。 

## Thinking4: 假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站指定基于内容的推荐系统，即用户看了某小说后，推荐其他相关的小说。原理和步骤是怎样的？
- 小说摘要的特征提取
    - N-Gram，提取N个连续字集合，作为特征
    - TF-IDF,TFIDF矩阵
- 计算文章摘要之间的相似度矩阵
    - 如余弦相似度衡量
- 算则相似度最大的Top-K个文章进行输出和推荐    

## Thinking5：Word2Vec的应用场景有哪些？
- Word2Vec 是word Embedding的重要方法之一。不仅能够将文本的稀疏One-hot表示，转换为更加紧凑，长度向相同的向量，而且根据所选的训练集的不同，这种向量的表示可以反映词语词之间的相似关系。
- 在NLP任务中，经常需要通过深度学习模型，分裂及生成文本。这种基于向量的词表示，更便于计算，而在推荐系统中，基于内容推荐场景中，可以通过计算物品描述关键词之间的相似度关系完成推荐